name: Build universe, screen, backtest & publish

on:
  workflow_dispatch: {}
  # optionnel : planifier un run quotidien à 22:15 Paris
  # schedule:
  #   - cron: "15 20 * * 1-5"

permissions:
  contents: write

concurrency:
  group: screener-${{ github.ref }}
  cancel-in-progress: false

jobs:
  run:
    runs-on: ubuntu-latest
    timeout-minutes: 45
    env:
      DEFAULT_BRANCH: main
      # Exposées à Python (fallback vers secrets, ou vide si non fournis)
      FINNHUB_API_KEY: ${{ secrets.FINNHUB_API_KEY }}
      ALPHAVANTAGE_API_KEY: ${{ secrets.ALPHAVANTAGE_API_KEY }}

    steps:
      - name: Checkout repo
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Ensure clean working tree (sync to origin)
        run: |
          set -euo pipefail
          git fetch origin $DEFAULT_BRANCH
          git reset --hard origin/$DEFAULT_BRANCH
          git clean -fd

      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'
          cache: 'pip'

      - name: Install dependencies
        run: |
          set -euo pipefail
          python -m pip install --upgrade pip
          pip install -r requirements.txt

      # ================== 1) UNIVERS ==================
      # Produit: raw_universe.csv + universe_in_scope.csv
      - name: Build filtered universe (<75B & sectors IT/HC/Financials/Industrials)
        run: |
          set -euo pipefail
          python build_universe.py

          echo "== HEAD raw_universe.csv =="
          head -n 5 raw_universe.csv || (echo "missing raw_universe.csv" && exit 1)

          echo "== HEAD universe_in_scope.csv =="
          head -n 10 universe_in_scope.csv || (echo "missing universe_in_scope.csv" && exit 1)

      # ================== 2) SECTEURS (pour heatmap/timeline) ==================
      # Produit: sector_catalog.csv, sector_history.csv, sector_breadth.csv
      - name: Build sector catalog & history
        run: |
          set -euo pipefail
          python build_sector_catalog.py

          for f in sector_catalog.csv sector_history.csv sector_breadth.csv; do
            if [ ! -f "dashboard/public/$f" ]; then
              echo "Missing dashboard/public/$f"; exit 1
            fi
            echo "--- head $f ---"; head -n 5 "dashboard/public/$f"
          done

      # ================== 3) SCREENER (cascade YF→TV→Finnhub / YF→Finnhub→AV) ==================
      # Produit: candidates_all_ranked.csv, confirmed_STRONGBUY.csv, anticipative_pre_signals.csv,
      #          event_driven_signals.csv, signals_history.csv
      - name: Run screener (cascade providers)
        env:
          PYTHONUNBUFFERED: "1"
          FINNHUB_API_KEY: ${{ env.FINNHUB_API_KEY }}
          ALPHAVANTAGE_API_KEY: ${{ env.ALPHAVANTAGE_API_KEY }}
        run: |
          set -euo pipefail
          python mix_ab_screen_indices.py

          # fichiers critiques
          for f in confirmed_STRONGBUY.csv candidates_all_ranked.csv signals_history.csv; do
            test -f "dashboard/public/$f" || (echo "Missing dashboard/public/$f"; exit 1)
            echo "--- head $f ---"; head -n 5 "dashboard/public/$f" || true
          done

      # ================== 4) BACKTEST ==================
      # Produit: backtest_* (trades, summary, equity 1/3/5/10/20d + SPY benchmarks + user)
      - name: Run backtest
        run: |
          set -euo pipefail
          python backtest_signals.py

          echo "== Backtest outputs (dashboard/public) =="
          req=(
            "backtest_trades.csv"
            "backtest_summary.csv"
            "backtest_equity_10d.csv"
            "backtest_benchmark_spy_10d.csv"
            "backtest_equity_10d_user.csv"
          )
          for f in "${req[@]}"; do
            if [ ! -f "dashboard/public/$f" ]; then
              echo "Missing dashboard/public/$f"; exit 1
            fi
            echo "--- head $f ---"; head -n 5 "dashboard/public/$f" || true
            echo "--- linecount $f ---"; wc -l "dashboard/public/$f" || true
          done

      # ================== 5) FEAR & GREED (alternative.me live) ==================
      # Produit: dashboard/public/fear_greed.json
      - name: Update Fear & Greed (alt.me live)
        run: |
          set -euo pipefail
          python fetch_alt_fng.py
          test -f "dashboard/public/fear_greed.json" || (echo "Missing dashboard/public/fear_greed.json"; exit 1)
          echo "--- fear_greed.json ---"
          head -c 400 dashboard/public/fear_greed.json; echo

      # ================== 6) DIAGNOSTIC GLOBAL ==================
      - name: Sanity dump (root + public)
        run: |
          set -euo pipefail
          echo "== ROOT (short) =="; ls -lah | sed -n '1,200p'
          echo "== dashboard/public (short) =="; ls -lah dashboard/public || true

      # ================== 7) COMMIT / PUSH ==================
      - name: Commit & push CSV/JSON updates
        run: |
          set -euo pipefail
          git config user.name "github-actions[bot]"
          git config user.email "41898282+github-actions[bot]@users.noreply.github.com"
          git add -A
          if git diff --cached --quiet; then
            echo "No CSV changes to commit."
            exit 0
          fi
          git commit -m "auto: update datasets ($(date -u +'%Y-%m-%dT%H:%M:%SZ'))"
          git pull --rebase origin $DEFAULT_BRANCH
          git push origin HEAD:$DEFAULT_BRANCH
          
      - name: Repair prices & market cap in candidates CSVs
        run: |
          python -m pip install --quiet --upgrade pip
          pip install --quiet pandas yfinance
          python tools/repair_candidates_prices.py

      - name: Clean sector_breadth
        run: |
          python tools/clean_sector_breadth.py
